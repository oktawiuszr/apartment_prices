{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7855f1a0",
   "metadata": {},
   "source": [
    "Data cleaning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cca77a",
   "metadata": {},
   "source": [
    "Sets organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = \"./../data/raw/\"\n",
    "\n",
    "rent = [file for file in os.listdir(path) if file.startswith(\"apartments_rent_pl\")]\n",
    "purchase = [file_2 for file_2 in os.listdir(path) if file_2.startswith(\"apartments_pl\")]\n",
    "\n",
    "print(rent, purchase)\n",
    "\n",
    "whole_rent = pd.DataFrame()\n",
    "whole_rent = whole_rent.to_csv(\"./../data/interim/1_whole_rent.csv\", index=False)\n",
    "\n",
    "whole_purchase = pd.DataFrame()\n",
    "whole_purchase.to_csv(\"./../data/interim/2_whole_purchase.csv\", index=False)\n",
    "\n",
    "combined_data = []\n",
    "combined_data2 = []\n",
    "\n",
    "for file in rent:\n",
    "    data = pd.read_csv(path + file)\n",
    "    time = file[-6:-4] + \"_\" + file[-9:-7]\n",
    "    print(time)\n",
    "    print(file)\n",
    "    data[\"Period\"] = time\n",
    "    combined_data.append(data)\n",
    "\n",
    "result = pd.concat(combined_data, ignore_index=True)\n",
    "result.to_csv(\"./../data/interim/1_whole_rent.csv\", index=False)\n",
    "\n",
    "for file_2 in purchase:\n",
    "    data = pd.read_csv(path + file_2)\n",
    "    time2 = file_2[-6:-4] + \"_\" + file_2[-9:-7]\n",
    "    print(time2)\n",
    "    data[\"Period\"] = time2\n",
    "    combined_data2.append(data)\n",
    "\n",
    "result2 = pd.concat(combined_data2, ignore_index=True)\n",
    "result2.to_csv(\"./../data/interim/2_whole_purchase.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb33cb4",
   "metadata": {},
   "source": [
    "Data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190294f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv(\"./../data/interim/1_whole_rent.csv\")\n",
    "print(\"Data of rent overview: \")\n",
    "print(\"\\n Shape od data\", data.shape)\n",
    "print(\"\\n Lack of values: \")\n",
    "print(data.isnull().sum())\n",
    "print(\"\\n Stats:\")\n",
    "print(data.describe(include='all'))\n",
    "\n",
    "data=pd.read_csv(\"./../data/interim/2_whole_purchase.csv\")\n",
    "print(\"Data of sales overview: \")\n",
    "print(\"\\n Shape od data\", data.shape)\n",
    "print(\"\\n Lack of values: \")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "\n",
    "print(\"\\n Stats:\")\n",
    "print(data.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee710873",
   "metadata": {},
   "source": [
    "1. For NaN in columns hasStorageRoom, hasSecurity, has Elevator, hasBalcony, and hasParkingSpace the NaN is filled with no\n",
    "For NaN in columns with distances, the NaN is  filled with distance to the center\n",
    "3. For Na in columns with condition, NaN is filled with \"Low\"\n",
    "4. Floor is  filled with floor count for apartment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46fb9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "fill_na_map = {'schoolDistance': \"centreDistance\", 'clinicDistance': \"centreDistance\", 'postOfficeDistance': \"centreDistance\",\n",
    "               'kindergartenDistance': \"centreDistance\", 'restaurantDistance': \"centreDistance\", 'collegeDistance': \"centreDistance\",\n",
    "               'pharmacyDistance': \"centreDistance\", \"floor\": \"floorCount\"}\n",
    "\n",
    "\n",
    "path = \"./../data/interim/\"\n",
    "files = os.listdir(path)\n",
    "print(files)\n",
    "print((pd.read_csv(path+files[0])).columns)\n",
    "\n",
    "for file in files:\n",
    "    data = pd.read_csv(path+file)\n",
    "    # Empty cells for elevator, parking space, security, balcony,ect. is filled with no\n",
    "    data.fillna({\"hasParkingSpace\": \"no\", 'hasBalcony': \"no\", 'hasElevator': \"no\", 'hasSecurity': \"no\",\n",
    "                'hasStorageRoom': \"no\", \"condition\": \"NoData\", \"buildingMaterial\": \"NoData\", \"type\": \"NoData\"}, inplace=True)\n",
    "\n",
    "    # Empty cells for distances from object is filled with distance to center\n",
    "    for target, source in fill_na_map.items():\n",
    "        data[target] = data[target].fillna(data[source])\n",
    "\n",
    "    # Random year for year, but in rang of 1850(minial)-1930.\n",
    "    nan_mask = data[\"buildYear\"].isna()\n",
    "    data.loc[nan_mask, \"buildYear\"] = np.random.randint(\n",
    "        1850, 1930, size=nan_mask.sum())\n",
    "    data = data.dropna(how='any')\n",
    "    data.to_csv(path+file, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88359f06",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"./../data/interim/1_whole_rent.csv\")\n",
    "print(\"Data of rent overview: \")\n",
    "print(\"\\n Shape od data\", data.shape)\n",
    "print(\"\\n Lack of values: \")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "data = pd.read_csv(\"./../data/interim/2_whole_purchase.csv\")\n",
    "print(\"Data of sales overview: \")\n",
    "print(\"\\n Shape od data\", data.shape)\n",
    "print(\"\\n Lack of values: \")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649a26a0",
   "metadata": {},
   "source": [
    "Wrocław, Warszawa, Lublin, Łódz, Radom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f357e7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = \"./../data/interim/\"\n",
    "files = os.listdir(path)\n",
    "print(files)\n",
    "\n",
    "for file in files:\n",
    "    data = pd.read_csv(path+file)\n",
    "    data = data[data[\"city\"].isin(\n",
    "        [\"krakow\", \"warszawa\", \"radom\", \"lublin\", \"wroclaw\"])]\n",
    "    print(data[\"city\"].unique())\n",
    "\n",
    "    # Additional cleaning\n",
    "    if \"Unnamed: 0\" in data.columns:\n",
    "        data.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "    int_columns = [\"rooms\", \"floor\", \"floorCount\", 'bulidYear']\n",
    "    for col in int_columns:\n",
    "        if col in data.columns:\n",
    "            data[col] = data[col].astype(\"Int64\")\n",
    "\n",
    "    binary_map = {\"yes\": True, \"no\": False, 'Yes': True, 'No': False}\n",
    "    binary_columns = ['hasParkingSpace', 'hasBalcony',\n",
    "                      'hasElevator', 'hasSecurity', 'hasStorageRoom']\n",
    "    for col in binary_columns:\n",
    "        if col in data.columns:\n",
    "            data[col] = data[col].map(binary_map)\n",
    "\n",
    "    if 'id' in data.columns:\n",
    "        data['id'] = data['id'].astype(str)\n",
    "\n",
    "    if 'buildYear' in data.columns:\n",
    "        current_year = pd.Timestamp.now().year\n",
    "        data['buildingAge'] = current_year - data['buildYear']\n",
    "        data.loc[(data['buildingAge'] < 0) | (data['buildingAge'] > 300)]\n",
    "\n",
    "    data.to_csv(\"./../data/processed/\"+file[0]+\"_analysis\"+file[7:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a05f3f",
   "metadata": {},
   "source": [
    "Data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4e6ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = \"./../data/processed/\"\n",
    "files = os.listdir(path)\n",
    "print(files)\n",
    "\n",
    "for file in files:\n",
    "    data = pd.read_csv(path+file)\n",
    "    print(\"\\n============== Check for \", file, \"===========\")\n",
    "    print(\"-------Missing values---------\")\n",
    "    print(data.isnull().sum())\n",
    "    print('\\n-----------Data Types------------')\n",
    "    print(data.dtypes)\n",
    "    print(\"\\n----------Duplicate Rows---------\")\n",
    "    print(data.duplicated().sum())\n",
    "    print(\"\\n--------Summary Statistics-------\")\n",
    "    print(data.describe(include=\"all\"))\n",
    "    print(\"\\n --------Unique values per column-----------\")\n",
    "    for col in data.columns:\n",
    "        unique_v = data[col] = data[col].nunique()\n",
    "        print(f\"{col}:{unique_v} unique values\")\n",
    "    print(\"\\n ------ Outliers Detection----\")\n",
    "    n_cols = data.select_dtypes(include=[\"number\"]).columns\n",
    "    for col in n_cols:\n",
    "        q1 = data[col].quantile(0.25)\n",
    "        q3 = data[col].quantile(0.75)\n",
    "        iqr = q3-q1\n",
    "        outliers = data[(data[col] < q1-1.5*iqr) | (data[col] > q3+1.5*iqr)]\n",
    "        print(f\"{col}:{len(outliers)} outliers\")\n",
    "\n",
    "    print(data.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
